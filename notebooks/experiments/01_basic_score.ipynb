{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd4f18da-3e86-4129-aa31-6575fbc87303",
   "metadata": {},
   "source": [
    "# Basic. Evalution\n",
    "\n",
    "* Ingest Pipeline:\n",
    "    * Simple PDF parsing\n",
    "    * Page chunking and indexing\n",
    "* Query Pipeline\n",
    "    * Basic retriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97a5a3e4-4348-46e9-a793-17c480ab7875",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78ba71f2-fdb9-4ab7-8153-3e4296288e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from ragas.evaluation import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "from src import chain, tags, rag_eval\n",
    "\n",
    "from src.mle import utils as mle_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1af7b5de-adf8-4ece-b5a6-9dc22036b413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\manua\\\\.conda\\\\envs\\\\rag-advanced\\\\python.exe'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f10460f6-4673-4f8c-9c3b-a7f02a1aa44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_pipeline = \"01basic\"\n",
    "folder_src = \"ai-papers\"\n",
    "index_name = \"ai-papers\"\n",
    "llm_emb = \"text-embedding-3-small\"\n",
    "retriever_k = 2\n",
    "retriever_treshold = 0.3\n",
    "temp = 0.2\n",
    "llm_model = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e188104e-1f1e-4288-8b8e-b99ce80afd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "embeddings = OpenAIEmbeddings(model=llm_emb)\n",
    "llm_qa = ChatOpenAI(model_name=llm_model, temperature=temp)\n",
    "llm_eval = ChatOpenAI(model_name=llm_model, temperature=0.1)\n",
    "\n",
    "\n",
    "path_corpus = mle_utils.path_data_raw / folder_src \n",
    "\n",
    "path_db = mle_utils.path_data_interm / index_name / \"chroma_langchain_db\"\n",
    "path_db.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "path_eval_ds = mle_utils.path_data_raw / \"eval-questions\" \n",
    "fln_eval_ds = path_eval_ds / f\"{index_name}.csv\"\n",
    "\n",
    "\n",
    "path_eval = mle_utils.path_data_processed /  \"evals\" / index_name\n",
    "path_eval.mkdir(exist_ok=True, parents=True)\n",
    "fln_eval_ragas = path_eval / f\"ragas-{id_pipeline}.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46ad787-7037-4db1-a6d1-83aa12dfe57c",
   "metadata": {},
   "source": [
    "# Query Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a0b5b13-4396-4dd2-ba35-7c2cad81e5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Chroma(\n",
    "    collection_name=index_name,\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=path_db.as_posix()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdd359ec-988f-460d-8ef0-269a20dc2cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:\n",
      "* Lag-Llama\n",
      "number of series is useful when sampling random windows\n",
      "from the pretraining corpus. Furth [{'extension': '.pdf', 'page': 4, 'source': 'lagllama'}]\n",
      "\n",
      "* Lag-Llama\n",
      "Dtest={xi\n",
      "Ti+1:Ti+P}D\n",
      "i=1.\n",
      "Theunivariate probabilistic time series forecasting problem\n",
      "inv [{'extension': '.pdf', 'page': 4, 'source': 'lagllama'}]\n",
      "\n",
      "Answer:  A total of 27 time series datasets are used to train the Lag-Llama model.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\":retriever_treshold, \"k\": retriever_k})\n",
    "chain_basic_rag = chain.rag_basic_with_sources(llm_qa , retriever)\n",
    "response = chain_basic_rag.invoke({'input': \"how many time series datasets are used to train lag-llama model?\"})\n",
    "\n",
    "print(\"Context:\")\n",
    "for context in response['context']:\n",
    "    print(f\"* {context.page_content[:100]} [{res.metadata}]\")\n",
    "    print()\n",
    "    \n",
    "print(\"Answer: \", response['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba5929d-bf60-43ac-8c01-d2da0bc15f0b",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40ca06a0-e371-4bfd-af13-eb951527fc17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper</th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>source</th>\n",
       "      <th>split_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mamba: Linear-Time Sequence Modeling with Sele...</td>\n",
       "      <td>What are the main limitations and risks associ...</td>\n",
       "      <td>While Mamba shows strong performance in variou...</td>\n",
       "      <td>Section 5</td>\n",
       "      <td>1.train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PaliGemma</td>\n",
       "      <td>How does PaliGemma perform compared to larger ...</td>\n",
       "      <td>PaliGemma, with less than 3B parameters, achie...</td>\n",
       "      <td>Introduction, Section 1; Results, Section 4</td>\n",
       "      <td>1.train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Llama 3</td>\n",
       "      <td>What ablation studies were conducted on Llama ...</td>\n",
       "      <td>Ablation studies focused on hyperparameters li...</td>\n",
       "      <td>Ablation Studies, Section 5</td>\n",
       "      <td>1.train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mamba: Linear-Time Sequence Modeling with Sele...</td>\n",
       "      <td>What is the hardware optimization that enables...</td>\n",
       "      <td>Mamba uses a hardware-aware parallel algorithm...</td>\n",
       "      <td>Abstract, Section 3.3</td>\n",
       "      <td>1.train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PaliGemma</td>\n",
       "      <td>How does PaliGemma achieve transferability acr...</td>\n",
       "      <td>PaliGemma uses a flexible fine-tuning approach...</td>\n",
       "      <td>Transferability, Section 6</td>\n",
       "      <td>1.train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lag-Llama</td>\n",
       "      <td>What is the choice of the distribution head us...</td>\n",
       "      <td>The model uses a Student's t-distribution head...</td>\n",
       "      <td>Section 4.3: Choice of Distribution Head</td>\n",
       "      <td>1.train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lag-Llama</td>\n",
       "      <td>What datasets were used to train and evaluate ...</td>\n",
       "      <td>The model was trained on 27 datasets across do...</td>\n",
       "      <td>Section 5.1: Datasets</td>\n",
       "      <td>1.train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ColPali</td>\n",
       "      <td>How does ColPali achieve faster indexing and q...</td>\n",
       "      <td>ColPali directly encodes pages from their imag...</td>\n",
       "      <td>Section 5.2, Latencies &amp; Memory Footprint</td>\n",
       "      <td>1.train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TimesFM</td>\n",
       "      <td>How does TimesFM handle long-horizon forecasts...</td>\n",
       "      <td>TimesFM uses longer output patches during deco...</td>\n",
       "      <td>Model Architecture, Section 4</td>\n",
       "      <td>1.train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TimesFM</td>\n",
       "      <td>What novelties does the TimesFM introduce in t...</td>\n",
       "      <td>The main novelties include a patched-decoder s...</td>\n",
       "      <td>Abstract, Introduction, Model Architecture</td>\n",
       "      <td>1.train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ColPali</td>\n",
       "      <td>What problem does ColPali aim to solve in docu...</td>\n",
       "      <td>ColPali addresses the inefficiencies in curren...</td>\n",
       "      <td>Abstract, Introduction</td>\n",
       "      <td>1.train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Llama 3</td>\n",
       "      <td>What strategies were used to scale the Llama 3...</td>\n",
       "      <td>Llama 3 uses 4D parallelism, combining tensor,...</td>\n",
       "      <td>Infrastructure, Section 3.3</td>\n",
       "      <td>1.train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                paper  \\\n",
       "0   Mamba: Linear-Time Sequence Modeling with Sele...   \n",
       "1                                           PaliGemma   \n",
       "2                                             Llama 3   \n",
       "3   Mamba: Linear-Time Sequence Modeling with Sele...   \n",
       "4                                           PaliGemma   \n",
       "5                                           Lag-Llama   \n",
       "6                                           Lag-Llama   \n",
       "7                                             ColPali   \n",
       "8                                             TimesFM   \n",
       "9                                             TimesFM   \n",
       "10                                            ColPali   \n",
       "11                                            Llama 3   \n",
       "\n",
       "                                             question  \\\n",
       "0   What are the main limitations and risks associ...   \n",
       "1   How does PaliGemma perform compared to larger ...   \n",
       "2   What ablation studies were conducted on Llama ...   \n",
       "3   What is the hardware optimization that enables...   \n",
       "4   How does PaliGemma achieve transferability acr...   \n",
       "5   What is the choice of the distribution head us...   \n",
       "6   What datasets were used to train and evaluate ...   \n",
       "7   How does ColPali achieve faster indexing and q...   \n",
       "8   How does TimesFM handle long-horizon forecasts...   \n",
       "9   What novelties does the TimesFM introduce in t...   \n",
       "10  What problem does ColPali aim to solve in docu...   \n",
       "11  What strategies were used to scale the Llama 3...   \n",
       "\n",
       "                                         ground_truth  \\\n",
       "0   While Mamba shows strong performance in variou...   \n",
       "1   PaliGemma, with less than 3B parameters, achie...   \n",
       "2   Ablation studies focused on hyperparameters li...   \n",
       "3   Mamba uses a hardware-aware parallel algorithm...   \n",
       "4   PaliGemma uses a flexible fine-tuning approach...   \n",
       "5   The model uses a Student's t-distribution head...   \n",
       "6   The model was trained on 27 datasets across do...   \n",
       "7   ColPali directly encodes pages from their imag...   \n",
       "8   TimesFM uses longer output patches during deco...   \n",
       "9   The main novelties include a patched-decoder s...   \n",
       "10  ColPali addresses the inefficiencies in curren...   \n",
       "11  Llama 3 uses 4D parallelism, combining tensor,...   \n",
       "\n",
       "                                         source   split_  \n",
       "0                                     Section 5  1.train  \n",
       "1   Introduction, Section 1; Results, Section 4  1.train  \n",
       "2                   Ablation Studies, Section 5  1.train  \n",
       "3                         Abstract, Section 3.3  1.train  \n",
       "4                    Transferability, Section 6  1.train  \n",
       "5      Section 4.3: Choice of Distribution Head  1.train  \n",
       "6                         Section 5.1: Datasets  1.train  \n",
       "7     Section 5.2, Latencies & Memory Footprint  1.train  \n",
       "8                 Model Architecture, Section 4  1.train  \n",
       "9    Abstract, Introduction, Model Architecture  1.train  \n",
       "10                       Abstract, Introduction  1.train  \n",
       "11                  Infrastructure, Section 3.3  1.train  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_label = mle_utils.Splits.TRAIN.value\n",
    "\n",
    "df_eval_qs = (pd.read_csv(fln_eval_ds)\n",
    "              .query(f\"{tags.SPLIT} == '{split_label}'\"))\n",
    "df_eval_qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35a560dd-6a9e-4d66-805b-529b409c7a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = rag_eval.populate_eval_dataset(\n",
    "    df_eval_qs,\n",
    "    chain_basic_rag\n",
    ")\n",
    "\n",
    "# https://www.databricks.com/blog/LLM-auto-eval-best-practices-RAG\n",
    "# https://docs.ragas.io/en/latest/references/evaluation.htmlS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4d981bac-fc69-4a06-9190-93d1dcc664bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context_relevancy': 0.0325, 'context_precision': 0.7500, 'context_recall': 0.5278, 'faithfulness': 0.5625, 'answer_relevancy': 0.5502}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = [\n",
    "            context_relevancy,\n",
    "            context_precision,\n",
    "            context_recall,\n",
    "            faithfulness,\n",
    "            answer_relevancy,\n",
    "        ]\n",
    "\n",
    "\n",
    "if fln_eval_ragas.exists():\n",
    "    with open(fln_eval_ragas, \"rb\") as file:\n",
    "        res_ragas_eval = pickle.load(file)\n",
    "\n",
    "else:  \n",
    "    res_ragas_eval = evaluate(\n",
    "        dataset=dataset,\n",
    "        metrics=[\n",
    "            context_relevancy,\n",
    "            context_precision,\n",
    "            context_recall,\n",
    "            faithfulness,\n",
    "            answer_relevancy,\n",
    "        ],\n",
    "        llm=llm_eval,\n",
    "        embeddings=embeddings\n",
    "    )\n",
    "    \n",
    "\n",
    "    with open(fln_ragas_eval, \"wb\") as file:\n",
    "        pickle.dump(res_ragas_eval, file)\n",
    "\n",
    "\n",
    "res_ragas_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b7b9a9d-f968-449c-9848-f60b064e3fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>context_relevancy</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the main limitations and risks associ...</td>\n",
       "      <td>No relevant information has been founded relat...</td>\n",
       "      <td>[Model Arch. Layer Acc.\\nS4 No gate S4 18.3\\n-...</td>\n",
       "      <td>While Mamba shows strong performance in variou...</td>\n",
       "      <td>0.012195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does PaliGemma perform compared to larger ...</td>\n",
       "      <td>PaliGemma, despite being a sub-3B vision-langu...</td>\n",
       "      <td>[July 2024\\nPaliGemma: A versatile 3B VLM for ...</td>\n",
       "      <td>PaliGemma, with less than 3B parameters, achie...</td>\n",
       "      <td>0.018405</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.811428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What ablation studies were conducted on Llama ...</td>\n",
       "      <td>No relevant information has been founded relat...</td>\n",
       "      <td>[Model Preference\\nPM for Llama 3 8B 60.0%\\nSt...</td>\n",
       "      <td>Ablation studies focused on hyperparameters li...</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the hardware optimization that enables...</td>\n",
       "      <td>No relevant information has been founded relat...</td>\n",
       "      <td>[/uni00000015/uni00000014/uni0000001a/uni00000...</td>\n",
       "      <td>Mamba uses a hardware-aware parallel algorithm...</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How does PaliGemma achieve transferability acr...</td>\n",
       "      <td>PaliGemma achieves transferability across diff...</td>\n",
       "      <td>[PaliGemma: A versatile 3B VLM for transfer\\nL...</td>\n",
       "      <td>PaliGemma uses a flexible fine-tuning approach...</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is the choice of the distribution head us...</td>\n",
       "      <td>The choice of the distribution head used in La...</td>\n",
       "      <td>[Lag-Llama\\nas in LLaMA (Touvron et al., 2023)...</td>\n",
       "      <td>The model uses a Student's t-distribution head...</td>\n",
       "      <td>0.016529</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.856607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What datasets were used to train and evaluate ...</td>\n",
       "      <td>No relevant information has been founded relat...</td>\n",
       "      <td>[Finetuned Multilingual Long context Tool use ...</td>\n",
       "      <td>The model was trained on 27 datasets across do...</td>\n",
       "      <td>0.005376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How does ColPali achieve faster indexing and q...</td>\n",
       "      <td>ColPali achieves faster indexing and querying ...</td>\n",
       "      <td>[Figure 2: ColPali simplifies document retriev...</td>\n",
       "      <td>ColPali directly encodes pages from their imag...</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How does TimesFM handle long-horizon forecasts...</td>\n",
       "      <td>TimesFM handles long-horizon forecasts by util...</td>\n",
       "      <td>[A decoder-only foundation model for time-seri...</td>\n",
       "      <td>TimesFM uses longer output patches during deco...</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.934344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What novelties does the TimesFM introduce in t...</td>\n",
       "      <td>No relevant information has been founded relat...</td>\n",
       "      <td>[A decoder-only foundation model for time-seri...</td>\n",
       "      <td>The main novelties include a patched-decoder s...</td>\n",
       "      <td>0.028409</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What problem does ColPali aim to solve in docu...</td>\n",
       "      <td>ColPali aims to solve the problem of efficient...</td>\n",
       "      <td>[Figure 2: ColPali simplifies document retriev...</td>\n",
       "      <td>ColPali addresses the inefficiencies in curren...</td>\n",
       "      <td>0.031847</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What strategies were used to scale the Llama 3...</td>\n",
       "      <td>The strategies used to scale the Llama 3 model...</td>\n",
       "      <td>[101010111012\\nTraining Tokens0.700.750.800.85...</td>\n",
       "      <td>Llama 3 uses 4D parallelism, combining tensor,...</td>\n",
       "      <td>0.162963</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0   What are the main limitations and risks associ...   \n",
       "1   How does PaliGemma perform compared to larger ...   \n",
       "2   What ablation studies were conducted on Llama ...   \n",
       "3   What is the hardware optimization that enables...   \n",
       "4   How does PaliGemma achieve transferability acr...   \n",
       "5   What is the choice of the distribution head us...   \n",
       "6   What datasets were used to train and evaluate ...   \n",
       "7   How does ColPali achieve faster indexing and q...   \n",
       "8   How does TimesFM handle long-horizon forecasts...   \n",
       "9   What novelties does the TimesFM introduce in t...   \n",
       "10  What problem does ColPali aim to solve in docu...   \n",
       "11  What strategies were used to scale the Llama 3...   \n",
       "\n",
       "                                               answer  \\\n",
       "0   No relevant information has been founded relat...   \n",
       "1   PaliGemma, despite being a sub-3B vision-langu...   \n",
       "2   No relevant information has been founded relat...   \n",
       "3   No relevant information has been founded relat...   \n",
       "4   PaliGemma achieves transferability across diff...   \n",
       "5   The choice of the distribution head used in La...   \n",
       "6   No relevant information has been founded relat...   \n",
       "7   ColPali achieves faster indexing and querying ...   \n",
       "8   TimesFM handles long-horizon forecasts by util...   \n",
       "9   No relevant information has been founded relat...   \n",
       "10  ColPali aims to solve the problem of efficient...   \n",
       "11  The strategies used to scale the Llama 3 model...   \n",
       "\n",
       "                                             contexts  \\\n",
       "0   [Model Arch. Layer Acc.\\nS4 No gate S4 18.3\\n-...   \n",
       "1   [July 2024\\nPaliGemma: A versatile 3B VLM for ...   \n",
       "2   [Model Preference\\nPM for Llama 3 8B 60.0%\\nSt...   \n",
       "3   [/uni00000015/uni00000014/uni0000001a/uni00000...   \n",
       "4   [PaliGemma: A versatile 3B VLM for transfer\\nL...   \n",
       "5   [Lag-Llama\\nas in LLaMA (Touvron et al., 2023)...   \n",
       "6   [Finetuned Multilingual Long context Tool use ...   \n",
       "7   [Figure 2: ColPali simplifies document retriev...   \n",
       "8   [A decoder-only foundation model for time-seri...   \n",
       "9   [A decoder-only foundation model for time-seri...   \n",
       "10  [Figure 2: ColPali simplifies document retriev...   \n",
       "11  [101010111012\\nTraining Tokens0.700.750.800.85...   \n",
       "\n",
       "                                         ground_truth  context_relevancy  \\\n",
       "0   While Mamba shows strong performance in variou...           0.012195   \n",
       "1   PaliGemma, with less than 3B parameters, achie...           0.018405   \n",
       "2   Ablation studies focused on hyperparameters li...           0.015385   \n",
       "3   Mamba uses a hardware-aware parallel algorithm...           0.008065   \n",
       "4   PaliGemma uses a flexible fine-tuning approach...           0.020202   \n",
       "5   The model uses a Student's t-distribution head...           0.016529   \n",
       "6   The model was trained on 27 datasets across do...           0.005376   \n",
       "7   ColPali directly encodes pages from their imag...           0.043478   \n",
       "8   TimesFM uses longer output patches during deco...           0.027027   \n",
       "9   The main novelties include a patched-decoder s...           0.028409   \n",
       "10  ColPali addresses the inefficiencies in curren...           0.031847   \n",
       "11  Llama 3 uses 4D parallelism, combining tensor,...           0.162963   \n",
       "\n",
       "    context_precision  context_recall  faithfulness  answer_relevancy  \n",
       "0                 0.0        0.000000        0.0000          0.000000  \n",
       "1                 1.0        1.000000        1.0000          0.811428  \n",
       "2                 0.0        0.000000        0.0000          0.000000  \n",
       "3                 1.0        0.000000        0.0000          0.000000  \n",
       "4                 1.0        0.333333        0.5625          1.000000  \n",
       "5                 1.0        1.000000        1.0000          0.856607  \n",
       "6                 0.0        0.000000        0.5000          0.000000  \n",
       "7                 1.0        1.000000        1.0000          1.000000  \n",
       "8                 1.0        1.000000        0.7500          0.934344  \n",
       "9                 1.0        1.000000        0.0000          0.000000  \n",
       "10                1.0        1.000000        1.0000          1.000000  \n",
       "11                1.0        0.000000        0.9375          1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ragas_eval = res_ragas_eval.to_pandas()\n",
    "df_ragas_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9920700e-e98a-475b-9b98-877a88773a02",
   "metadata": {},
   "source": [
    "# Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ed2050f9-a055-447d-a971-140591e56e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langfuse import Langfuse\n",
    "\n",
    "langfuse = Langfuse()\n",
    "langfuse.auth_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1378379f-2abd-456b-9437-ae374a62b46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ragas_eval_traces = trace_evaluation(\n",
    "    langfuse,\n",
    "    f\"{id_pipeline}_ragas\",\n",
    "    df_ragas_eval,\n",
    "    [metric.name for metric in metrics]\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
