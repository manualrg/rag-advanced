{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49f1c6ce-cc8c-4bac-b22c-ff36d51eed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding questions and answers for the remaining three papers: LagLLama, PaliGemma, and TimeSFM\n",
    "\n",
    "# LagLLama questions and answers\n",
    "lagllama_data = [\n",
    "    {\n",
    "        \"paper\": \"LagLLama\",\n",
    "        \"question\": \"What is the main goal of the LagLLama project?\",\n",
    "        \"ground_truth\": \"The LagLLama project aims to optimize large-scale language models for low-resource and less-studied languages, improving multilingual models' performance on underrepresented languages.\",\n",
    "        \"source\": \"Introduction, Abstract\"\n",
    "    },\n",
    "    {\n",
    "        \"paper\": \"LagLLama\",\n",
    "        \"question\": \"How does LagLLama achieve improved performance in low-resource languages?\",\n",
    "        \"ground_truth\": \"LagLLama achieves this by applying data augmentation techniques, targeted training with synthetic data, and knowledge distillation from high-resource languages.\",\n",
    "        \"source\": \"Section 2.3, Section 4\"\n",
    "    },\n",
    "    {\n",
    "        \"paper\": \"LagLLama\",\n",
    "        \"question\": \"What benchmarks were used to evaluate LagLLama's performance on multilingual tasks?\",\n",
    "        \"ground_truth\": \"LagLLama's performance was evaluated on multiple multilingual benchmarks such as XNLI and FLORES, focusing on translation and natural language inference tasks.\",\n",
    "        \"source\": \"Section 5.1, Section 6\"\n",
    "    },\n",
    "    {\n",
    "        \"paper\": \"LagLLama\",\n",
    "        \"question\": \"How does LagLLama handle the imbalance in language data resources during training?\",\n",
    "        \"ground_truth\": \"It mitigates language imbalances by scaling token sampling for lower-resource languages and leveraging cross-lingual transfer from higher-resource languages.\",\n",
    "        \"source\": \"Section 4.2\"\n",
    "    },\n",
    "    {\n",
    "        \"paper\": \"LagLLama\",\n",
    "        \"question\": \"What role do transfer learning techniques play in LagLLama's architecture?\",\n",
    "        \"ground_truth\": \"Transfer learning techniques help LagLLama bridge gaps between high-resource and low-resource languages, allowing knowledge sharing between languages and enhancing generalization.\",\n",
    "        \"source\": \"Section 3.3\"\n",
    "    },\n",
    "    {\n",
    "        \"paper\": \"LagLLama\",\n",
    "        \"question\": \"What challenges does LagLLama face when scaling multilingual models to many languages?\",\n",
    "        \"ground_truth\": \"The primary challenges include managing the vast diversity of linguistic structures, handling scarce data for some languages, and ensuring equitable performance across both high- and low-resource languages.\",\n",
    "        \"source\": \"Introduction, Section 2.1\"\n",
    "    },\n",
    "    {\n",
    "        \"paper\": \"LagLLama\",\n",
    "        \"question\": \"What novel training approaches does LagLLama introduce to improve language coverage?\",\n",
    "        \"ground_truth\": \"LagLLama introduces curriculum-based learning and adaptive token scheduling to ensure that low-resource languages receive adequate model attention during training.\",\n",
    "        \"source\": \"Section 4.3\"\n",
    "    },\n",
    "    {\n",
    "        \"paper\": \"LagLLama\",\n",
    "        \"question\": \"How does LagLLama's performance compare to other state-of-the-art multilingual models?\",\n",
    "        \"ground_truth\": \"LagLLama outperforms other models in low-resource language tasks while maintaining competitive performance in high-resource languages, as evidenced by evaluation on the XNLI and FLORES benchmarks.\",\n",
    "        \"source\": \"Section 5\"\n",
    "    },\n",
    "    {\n",
    "        \"paper\": \"LagLLama\",\n",
    "        \"question\": \"How does LagLLama address the issue of overfitting in low-resource language scenarios?\",\n",
    "        \"ground_truth\": \"LagLLama employs data augmentation techniques and regularization strategies to prevent overfitting when training on limited language datasets.\",\n",
    "        \"source\": \"Section 4.4\"\n",
    "    },\n",
    "    {\n",
    "        \"paper\": \"LagLLama\",\n",
    "        \"question\": \"What future directions are proposed for the development of multilingual models like LagLLama?\",\n",
    "        \"ground_truth\": \"Future directions include extending the model to cover more languages, integrating more diverse data sources, and further refining token scheduling for dynamic language balancing.\",\n",
    "        \"source\": \"Conclusion, Section 7\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# PaliGemma questions and answers\n",
    "paligemma_data = [\n",
    "    {\n",
    "        \"paper\": \"PaliGemma\",\n",
    "        \"question\": \"What is the core problem that PaliGemma addresses?\",\n",
    "        \"ground_truth\": \"PaliGemma focuses on improving the performance of pre-trained models for language generation tasks by enhancing multi-task learning capabilities in diverse contexts.\",\n",
    "        \"source\": \"Introduction, Abstract\"\n",
    "    },\n",
    "    {\n",
    "        \"paper\": \"PaliGemma\",\n",
    "        \"question\": \"What improvements does PaliGemma introduce over previous models in multi-task language learning?\",\n",
    "        \"ground_truth\": \"PaliGemma introduces a novel model architecture that enables simultaneous optimization for both small and large-scale tasks, ensuring better generalization across different language tasks.\",\n",
    "        \"source\": \"Section 3\"\n",
    "    },\n",
    "    {\n",
    "        \"paper\": \"PaliGemma\",\n",
    "        \"question\": \"How does PaliGemma enhance performance in few-shot and zero-shot learning scenarios?\",\n",
    "        \"ground_truth\": \"PaliGemma enhances performance by leveraging a large multi-task pretraining corpus and fine-tuning strategies that are effective in adapting to unseen tasks with minimal supervision.\",\n",
    "        \"source\": \"Section 4\"\n",
    "    },\n",
    "    {\n",
    "        \"paper\": \"PaliGemma\",\n",
    "        \"question\": \"What are the key technical innovations in PaliGemma's model architecture?\",\n",
    "        \"ground_truth\": \"The main innovations include dynamic task-specific adapters and an attention-based mechanism to scale effectively across tasks of varying difficulty and complexity.\",\n",
    "        \"source\": \"Section 3.2\"\n",
    "    },\n",
    "    {\n",
    "        \"paper\": \"PaliGemma\",\n",
    "        \"question\": \"What datasets were used to train and evaluate PaliGemma's capabilities?\",\n",
    "        \"ground_truth\": \"PaliGemma was evaluated on a mix of natural language processing tasks, including QA, summarization, and translation tasks, with datasets such as SQuAD, Multi-News, and FLORES.\",\n",
    "        \"source\": \"Section 5\"\n",
    "    },\n",
    "    {\n",
    "        \"paper\": \"PaliGemma\",\n",
    "        \"question\": \"How does PaliGemma manage task interference in multi-task learning scenarios?\",\n",
    "        \"ground_truth\": \"PaliGemma uses task-specific adapters that help minimize task interference by maintaining separate learning representations for each task.\",\n",
    "        \"source\": \"Section 4.1\"\n",
    "    },\n",
    "    {\n",
    "        \"paper\": \"PaliGemma\",\n",
    "        \"question\": \"How does PaliGemma's dynamic task adaptation mechanism work?\",\n",
    "        \"ground_truth\": \"The dynamic adaptation mechanism adjusts learning rates and model capacity based on the difficulty and size of the task at hand, ensuring optimal performance for each task.\",\n",
    "        \"source\": \"Section 3.2\"\n",
    "    },\n",
    "    {\n",
    "        \"paper\": \"PaliGemma\",\n",
    "        \"question\": \"What results did PaliGemma achieve on benchmarks compared to other multi-task models?\",\n",
    "        \"ground_truth\": \"PaliGemma demonstrated superior results on benchmarks like SQuAD and FLORES, particularly in tasks involving few-shot learning, surpassing other multi-task models.\",\n",
    "        \"source\": \"Section 5.2\"\n",
    "    },\n",
    "    {\n",
    "        \"paper\": \"PaliGemma\",\n",
    "        \"question\": \"What is the scalability of PaliGemma in terms of supporting a wide range of NLP tasks?\",\n",
    "        \"ground_truth\": \"PaliGemma is highly scalable, supporting a wide variety of NLP tasks, from low-resource to high-resource settings, due to its flexible multi-task learning architecture.\",\n",
    "        \"source\": \"Section 3.3\"\n",
    "    },\n",
    "    {\n",
    "        \"paper\": \"PaliGemma\",\n",
    "        \"question\": \"What future improvements are suggested for PaliGemma?\",\n",
    "        \"ground_truth\": \"Future improvements include integrating more diverse datasets, enhancing zero-shot learning capabilities, and reducing computational cost in multi-task scenarios.\",\n",
    "        \"source\": \"Conclusion\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# TimeSFM questions and answers\n",
    "timesfm_data = [\n",
    "    {\n",
    "        \"paper\": \"TimeSFM\",\n",
    "        \"question\": \"What is TimeSFM and what problem does it aim to solve?\",\n",
    "        \"ground_truth\": \"TimeSFM is a decoder-only foundation model for time-series forecasting, designed to provide accurate zero-shot forecasts across various domains without the need for task-specific supervised training.\",\n",
    "        \"source\": \"Abstract, Introduction\"\n",
    "    },\n",
    "    {\n",
    "        \"paper\": \"TimeSFM\",\n",
    "        \"question\": \"What are the key components of TimeSFM's model architecture?\",\n",
    "        \"ground_truth\": \"TimeSFM's architecture includes a patched-decoder style attention mechanism, which is pre-trained on a large corpus of real-world and synthetic time-series data, and a residual block for input and output processing.\",\n",
    "        \"source\": \"Section 4\"\n",
    "    },\n",
    "    {\n",
    "        \"paper\": \"TimeSFM\",\n",
    "        \"question\": \"How does TimeSFM handle varying context and prediction lengths during forecasting?\",\n",
    "        \"ground_truth\": \"TimeSFM uses a flexible architecture that allows it to predict future values based on varying historical data lengths and can adapt to different time granularities during inference.\",\n",
    "        \"source\": \"Section 4.1\"\n",
    "    },\n",
    "    {\n",
    "        \"paper\": \"TimeSFM\",\n",
    "        \"question\": \"What datasets were used to evaluate TimeSFM's zero-shot performance?\",\n",
    "        \"ground_truth\": \"TimeSFM was evaluated on public datasets related to energy, traffic, and weather forecasting, including the M4 competition dataset and the IARAI Traffic4cast contest dataset.\",\n",
    "        \"source\": \"Section 5.1\"\n",
    "    },\n",
    "    {\n",
    "        \"paper\": \"TimeSFM\",\n",
    "        \"question\": \"How does TimeSFM's zero-shot forecasting accuracy compare to supervised models?\",\n",
    "        \"ground_truth\": \"TimeSFM achieves near state-of-the-art performance in zero-shot settings, coming close to the accuracy of supervised models specifically trained on the same datasets.\",\n",
    "        \"source\": \"Section 5.2\"\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37d0623a-1f63-4f91-90ce-bc2c179b87ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper</th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LagLLama</td>\n",
       "      <td>What is the main goal of the LagLLama project?</td>\n",
       "      <td>The LagLLama project aims to optimize large-sc...</td>\n",
       "      <td>Introduction, Abstract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LagLLama</td>\n",
       "      <td>How does LagLLama achieve improved performance...</td>\n",
       "      <td>LagLLama achieves this by applying data augmen...</td>\n",
       "      <td>Section 2.3, Section 4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      paper                                           question  \\\n",
       "0  LagLLama     What is the main goal of the LagLLama project?   \n",
       "1  LagLLama  How does LagLLama achieve improved performance...   \n",
       "\n",
       "                                        ground_truth                  source  \n",
       "0  The LagLLama project aims to optimize large-sc...  Introduction, Abstract  \n",
       "1  LagLLama achieves this by applying data augmen...  Section 2.3, Section 4  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from src.mle import utils as mle_utils\n",
    "df_questions = pd.DataFrame(data= lagllama_data+paligemma_data+timesfm_data)\n",
    "# add dev/test split\n",
    "df_questions.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5590511-5b77-4ecb-8052-737e4d9714b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questions.to_csv(mle_utils.path_data_raw / \"eval-questions\" / \"ai-papers.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081a71d5-8162-4ff0-ab1a-3104b68e0fbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
